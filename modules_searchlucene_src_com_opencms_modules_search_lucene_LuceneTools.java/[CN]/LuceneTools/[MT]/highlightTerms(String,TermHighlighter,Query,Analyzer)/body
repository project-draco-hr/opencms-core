{
  StringBuffer newText=new StringBuffer();
  TokenStream stream=null;
  try {
    HashSet terms=new HashSet();
    org.apache.lucene.analysis.Token token;
    String tokenText;
    int startOffset;
    int endOffset;
    int lastEndOffset=0;
    getTerms(query,terms,false);
    stream=analyzer.tokenStream(new StringReader(text));
    while ((token=stream.next()) != null) {
      startOffset=token.startOffset();
      endOffset=token.endOffset();
      tokenText=text.substring(startOffset,endOffset);
      if (startOffset > lastEndOffset)       newText.append(text.substring(lastEndOffset,startOffset));
      if (terms.contains(token.termText()))       newText.append(highlighter.highlightTerm(tokenText));
 else       newText.append(tokenText);
      lastEndOffset=endOffset;
    }
    if (lastEndOffset < text.length())     newText.append(text.substring(lastEndOffset));
    return newText.toString();
  }
  finally {
    if (stream != null) {
      try {
        stream.close();
      }
 catch (      Exception e) {
      }
    }
  }
}
